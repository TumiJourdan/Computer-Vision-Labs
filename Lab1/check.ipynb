{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "import imageio\n",
    "import mpmath\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import PIL\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "from skimage.filters import prewitt_v, prewitt_h, laplace, threshold_otsu\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getFeatures(training_img, mask, show_plot=True):\n",
    "    binary_mask = mask>0.5\n",
    "    #plt.imshow(binary_mask)\n",
    "    \n",
    "    #add dimensions\n",
    "    # print(binary_mask.shape)\n",
    "    hsv_training_img = cv2.cvtColor(training_img, cv2.COLOR_BGR2RGB)\n",
    "    v,s,h = cv2.split(hsv_training_img)\n",
    "    h, s,v = h*binary_mask, s*binary_mask, v*binary_mask\n",
    "    # print(h.shape)\n",
    "    b,g,r = cv2.split(training_img)\n",
    "    r,g,b = r*binary_mask, g*binary_mask, b*binary_mask\n",
    "\n",
    "    # get vertical prewitt for separated channels\n",
    "    vert_prewitt_r = prewitt_v(image=r)\n",
    "    vert_prewitt_g = prewitt_v(image=g)\n",
    "    vert_prewitt_b = prewitt_v(image=b)\n",
    "\n",
    "    # get horizontal prewitt for separated channels\n",
    "    hori_prewitt_r = prewitt_h(image=r)\n",
    "    hori_prewitt_g = prewitt_h(image=g)\n",
    "    hori_prewitt_b = prewitt_h(image=b)\n",
    "\n",
    "    # get Laplacian for separated channels\n",
    "    laplace_r = laplace(image=r)\n",
    "    laplace_g = laplace(image=g)\n",
    "    laplace_b = laplace(image=b)\n",
    "\n",
    "\n",
    "    if show_plot:\n",
    "        # vertical prewitt plot \n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(16,4))\n",
    "        plt.subplot(1,3,1), plt.imshow( vert_prewitt_r,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.subplot(1,3,2), plt.imshow( vert_prewitt_g,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.subplot(1,3,3), plt.imshow( vert_prewitt_b,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.suptitle(\"Vertical Prewitt of RGB image\")\n",
    "        plt.show()\n",
    "\n",
    "        # horizontal prewitt plot\n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(16,4))\n",
    "        plt.subplot(1,3,1), plt.imshow( hori_prewitt_r,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.subplot(1,3,2), plt.imshow( hori_prewitt_g,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.subplot(1,3,3), plt.imshow( hori_prewitt_b,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.suptitle(\"Horizontal Prewitt of RGB image\")\n",
    "        plt.show()\n",
    "\n",
    "        # laplace plot\n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(16,4))\n",
    "        plt.subplot(1,3,1), plt.imshow( laplace_r,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.subplot(1,3,2), plt.imshow( laplace_g,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.subplot(1,3,3), plt.imshow( laplace_b,cmap=\"gray\"), plt.axis(\"off\")\n",
    "        plt.suptitle(\"Laplacian of RGB image\")\n",
    "        plt.show()\n",
    "\n",
    "    features = [\n",
    "        vert_prewitt_r, hori_prewitt_r,\n",
    "        vert_prewitt_g, hori_prewitt_g,\n",
    "        vert_prewitt_b, hori_prewitt_b,\n",
    "        laplace_r, laplace_g, laplace_b,\n",
    "        r, g, b,\n",
    "        h, s, v\n",
    "    ]\n",
    "\n",
    "    flattened_features = np.array([f[binary_mask].flatten() for f in features])\n",
    "    print(flattened_features[0].shape)\n",
    "\n",
    "    return np.array(flattened_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# NOTE pass the mask now\n",
    "def foreground_given_pixel(x,fg_mean, fg_cov, bg_mean, bg_cov,mask):\n",
    "    N_fg = np.sum(mask)\n",
    "    N_bg = 270_000 - N_fg\n",
    "    numerator = multivariate_normal.pdf( x, mean = fg_mean, cov= fg_cov, allow_singular=True) * (N_fg)\n",
    "    denominator = multivariate_normal.pdf(x, mean=fg_mean, cov=fg_cov, allow_singular=True)*N_fg \\\n",
    "                + multivariate_normal.pdf( x, mean= bg_mean, cov= bg_cov, allow_singular=True) * (N_bg)\n",
    "    probability = numerator/denominator\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPixelFeatures(features,row, col):\n",
    "    pixel_coordinate = row*600 + col\n",
    "    pixel_features= []\n",
    "    for f in features:\n",
    "        pixel_features.append(f[pixel_coordinate])\n",
    "    return pixel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270000,)\n",
      "(74573,)\n",
      "(195427,)\n"
     ]
    }
   ],
   "source": [
    "original = imread(\"Images/image-35.jpg\")\n",
    "\n",
    "mask = imread(\"Images/mask-35.png\", as_gray=True)\n",
    "#threshold mask\n",
    "mask = (mask>0.5).astype(int)\n",
    "# print(np.unique(mask))\n",
    "identity = np.ones_like(mask,int)\n",
    "inverse_mask = (mask <=0.5).astype(int)\n",
    "\n",
    "# feature extraction\n",
    "# get the feature for fg and bg\n",
    "original_features = getFeatures(original, identity, show_plot=False)\n",
    "# print(original_features.shape)\n",
    "fg_features = getFeatures(original, mask, show_plot=False)\n",
    "# print(fg_features[0].shape)\n",
    "bg_features = getFeatures(original, inverse_mask, show_plot=False)\n",
    "# print(bg_features[0].shape)\n",
    "\n",
    "# pixel as row with features in the col indices\n",
    "original_feature_matrix = np.stack(original_features, axis=-1)\n",
    "# print(original_feature_matrix.shape)\n",
    "\n",
    "fg_feature_matrix = np.stack(fg_features, axis=-1)\n",
    "# print(fg_feature_matrix.shape)\n",
    "fg_mean_vector = np.mean(fg_feature_matrix, axis=0)\n",
    "fg_cov_matrix = np.cov(fg_feature_matrix, rowvar=False)\n",
    "# print(fg_mean_vector.shape)\n",
    "# print(fg_cov_matrix.shape)\n",
    "bg_feature_matrix = np.stack(bg_features, axis=-1)\n",
    "bg_mean_vector = np.mean(bg_feature_matrix, axis=0)\n",
    "bg_cov_matrix = np.cov(bg_feature_matrix, rowvar=False)\n",
    "\n",
    "#======= Validation image ======\n",
    "validation_img = imread(\"Images/image-83.jpg\")\n",
    "# this is only used for the accuracy measure since it represents the foreground\n",
    "validation_mask = imread(\"Images/mask-83.png\", as_gray=True)\n",
    "# use null mask since we want to classify evey pixel in the validation image\n",
    "validation_features  = getFeatures(validation_img, null, show_plot=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
